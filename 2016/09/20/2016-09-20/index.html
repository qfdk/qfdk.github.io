<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Apache Spark with Pipeline and LDA | qfdk&#39;s projects</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="最近入坑Apache Spark，这个分布式框架让我知道了什么叫做大数据，以及在处理大数据之中所碰到的一些问题。首先说明一下语言当然用Scala 虽然一开始让人感觉比较反人类，但是经过一段时间的摸索发现真的挺好用的，甚至喜欢上了它，前提是不报错。
说一下工作环境:

Scala IED 
Scala  2.10.6
Apache Spark 1.6.1
Apache Zepprlin

这些版本要">
<meta property="og:type" content="article">
<meta property="og:title" content="Apache Spark with Pipeline and LDA">
<meta property="og:url" content="http://qfdk.github.io/2016/09/20/2016-09-20/index.html">
<meta property="og:site_name" content="qfdk's projects">
<meta property="og:description" content="最近入坑Apache Spark，这个分布式框架让我知道了什么叫做大数据，以及在处理大数据之中所碰到的一些问题。首先说明一下语言当然用Scala 虽然一开始让人感觉比较反人类，但是经过一段时间的摸索发现真的挺好用的，甚至喜欢上了它，前提是不报错。
说一下工作环境:

Scala IED 
Scala  2.10.6
Apache Spark 1.6.1
Apache Zepprlin

这些版本要">
<meta property="og:image" content="http://blog.qfdk.me/_image/2016-09-20-19-18-43.jpg">
<meta property="og:image" content="http://blog.qfdk.me/_image/2016-09-20-19-35-12.jpg">
<meta property="og:image" content="http://blog.qfdk.me/_image/2016-09-20-19-45-43.jpg">
<meta property="og:updated_time" content="2016-10-17T19:55:35.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Apache Spark with Pipeline and LDA">
<meta name="twitter:description" content="最近入坑Apache Spark，这个分布式框架让我知道了什么叫做大数据，以及在处理大数据之中所碰到的一些问题。首先说明一下语言当然用Scala 虽然一开始让人感觉比较反人类，但是经过一段时间的摸索发现真的挺好用的，甚至喜欢上了它，前提是不报错。
说一下工作环境:

Scala IED 
Scala  2.10.6
Apache Spark 1.6.1
Apache Zepprlin

这些版本要">
<meta name="twitter:image" content="http://blog.qfdk.me/_image/2016-09-20-19-18-43.jpg">
  
    <link rel="alternate" href="/atom.xml" title="qfdk&#39;s projects" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">qfdk&#39;s projects</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://qfdk.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-2016-09-20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/09/20/2016-09-20/" class="article-date">
  <time datetime="2016-09-20T17:08:00.000Z" itemprop="datePublished">2016-09-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Bigdata/">Bigdata</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Apache Spark with Pipeline and LDA
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>最近入坑Apache Spark，这个分布式框架让我知道了什么叫做大数据，以及在处理大数据之中所碰到的一些问题。首先说明一下语言当然用Scala 虽然一开始让人感觉比较反人类，但是经过一段时间的摸索发现真的挺好用的，甚至喜欢上了它，前提是不报错。</p>
<p>说一下工作环境:</p>
<ul>
<li>Scala IED </li>
<li>Scala  2.10.6</li>
<li>Apache Spark 1.6.1</li>
<li>Apache Zepprlin</li>
</ul>
<p>这些版本要对应起来，要不然吃不了兜着走。这里集群的管理工具是ambari，这个工具可以让你轻松的进行图像可视化。</p>
<p><img src="http://blog.qfdk.me/_image/2016-09-20-19-18-43.jpg" class="img-responsive" alt="ambai"></p>
<p>这里我们用的是 <code>Spark on Yarn</code> 模式，其中进行提交任务又有两种模式，这里简单的说一句，这两种模式分别为</p>
<ul>
<li>yarn-cluster : driver运行在container之中，所有的日志本地看不到，只能看到running的信息。</li>
<li>yarn-client : drivier运行在client中，可以看到所有的日志，测试比较方便。</li>
</ul>
<p>机器学习分为两个比较大的步骤: 收集预处理数据；进行学习</p>
<h2 id="收集预处理数据"><a href="#收集预处理数据" class="headerlink" title="收集预处理数据"></a>收集预处理数据</h2><p>这里当然选择到处都看得到的数据了，比如法国政府的 一些数据，<a href="https://www.data.gouv.fr/fr/datasets/boamp/" target="_blank" rel="external">https://www.data.gouv.fr/fr/datasets/boamp/</a> 这里好多数据，这里挑选他们的招标信息。这里选择2016年的，进行处理和学习。文件是tgz格式的，利用命令解压，最后得到一堆xml文件，对于这些文件可以利用 <a href="https://github.com/databricks/spark-xml" target="_blank" rel="external">https://github.com/databricks/spark-xml</a> 进行处理，处理方式很简单。<br>命令方式引用外部库<br><code>$SPARK_HOME/bin/spark-shell --packages com.databricks:spark-xml_2.10:0.4.0</code><br>简单的例子<br><code>$ wget https://github.com/databricks/spark-xml/raw/master/src/test/resources/books.xml</code></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SQLContext</span></div><div class="line"></div><div class="line"><span class="keyword">val</span> sqlContext = <span class="keyword">new</span> <span class="type">SQLContext</span>(sc)</div><div class="line"><span class="keyword">val</span> df = sqlContext.read</div><div class="line">    .format(&amp;quot;com.databricks.spark.xml&amp;quot;)</div><div class="line">    .option(&amp;quot;rowTag&amp;quot;, &amp;quot;book&amp;quot;)</div><div class="line">    .load(&amp;quot;books.xml&amp;quot;)</div><div class="line"></div><div class="line"><span class="keyword">val</span> selectedData = df.select(&amp;quot;author&amp;quot;, &amp;quot;_id&amp;quot;)</div></pre></td></tr></table></figure>
<p>这里了选择相应的表情进行选择，这里我选择“OBJET_COMPLET”和”LIBELLE”，当然路径可以是hdfs的路径，最后你会得到一个DataFrame的类型</p>
<p><img src="http://blog.qfdk.me/_image/2016-09-20-19-35-12.jpg" alt=""></p>
<p>就是一个数据表，这个数据表中包含着各种奇葩的数据，错别字等等都会再这里找到，还有null的情况,这些都是要处理掉然后进行学习，学习的目的是找到对应的TOPIC也就是主题。就直接上代码吧，建立一个scala的类。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">LDAml</span>(<span class="params"></span>) </span>&#123;</div><div class="line">    </div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">lda</span></span>(dataset: <span class="type">DataFrame</span>, sc: <span class="type">SparkContext</span>, inputCol: <span class="type">String</span>,</div><div class="line">          numbTopic: <span class="type">Int</span>, <span class="type">MaxIterations</span>: <span class="type">Int</span>,</div><div class="line">          vocabSize: <span class="type">Int</span>) = &#123;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> (documents, vocabArray, model) = preprocess(dataset, inputCol, sc, vocabSize)</div><div class="line">    <span class="keyword">val</span> corpus = documents.cache() <span class="comment">// use cache</span></div><div class="line">    <span class="keyword">val</span> corpusSize = corpus.count()</div><div class="line">    <span class="comment">/**</span></div><div class="line">     * Configure and run LDA</div><div class="line">     */</div><div class="line">    <span class="keyword">val</span> mbf = &#123;</div><div class="line">      <span class="comment">// add (1.0 / actualCorpusSize) to MiniBatchFraction be more robust on tiny datasets.</span></div><div class="line">      <span class="number">2.0</span> / <span class="type">MaxIterations</span> + <span class="number">1.0</span> / corpusSize</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// running lda</span></div><div class="line">    <span class="keyword">val</span> lda = <span class="keyword">new</span> <span class="type">LDA</span>()</div><div class="line">      .setK(numbTopic)</div><div class="line">      .setMaxIterations(<span class="type">MaxIterations</span>)</div><div class="line">      .setOptimizer(<span class="keyword">new</span> <span class="type">OnlineLDAOptimizer</span>().setMiniBatchFraction(math.min(<span class="number">1.0</span>, mbf))) <span class="comment">//add optimizer</span></div><div class="line">      .setDocConcentration(<span class="number">-1</span>) <span class="comment">// use default symmetric document-topic prior</span></div><div class="line">      .setTopicConcentration(<span class="number">-1</span>) <span class="comment">// use default symmetric topic-word prior</span></div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">     * Print results.</div><div class="line">     */</div><div class="line">    <span class="keyword">val</span> startTime = <span class="type">System</span>.nanoTime()</div><div class="line">    <span class="keyword">val</span> ldaModel = lda.run(corpus)</div><div class="line">    <span class="keyword">val</span> elapsed = (<span class="type">System</span>.nanoTime() - startTime) / <span class="number">1e9</span></div><div class="line"></div><div class="line">    ldaModel.save(sc, sc.getConf.get(&amp;quot;spark.client.ldamodelPath&amp;quot;))</div><div class="line"></div><div class="line">    <span class="comment">/************************************************************************</span></div><div class="line">     * Print results. for Zeppelin</div><div class="line">     ************************************************************************/</div><div class="line">    <span class="comment">// Print training time</span></div><div class="line">    println(s&amp;quot;<span class="type">Finished</span> training <span class="type">LDA</span> model.  <span class="type">Summary</span>:&amp;quot;)</div><div class="line">    println(s&amp;quot;<span class="type">Training</span> time (sec)\t$elapsed&amp;quot;)</div><div class="line">    println(s&amp;quot;==========&amp;quot;)</div><div class="line"></div><div class="line">    <span class="comment">// Print the topics, showing the top-weighted terms for each topic.</span></div><div class="line">    <span class="keyword">val</span> topicIndices = ldaModel.describeTopics(maxTermsPerTopic = <span class="number">5</span>)</div><div class="line">    <span class="keyword">val</span> topics = topicIndices.map &#123;</div><div class="line">      <span class="keyword">case</span> (terms, termWeights) =&amp;gt;</div><div class="line">        terms.map(vocabArray(_)).zip(termWeights)</div><div class="line">    &#125;</div><div class="line">    println(s&amp;quot;$numbTopic topics:&amp;quot;)</div><div class="line">    topics.zipWithIndex.foreach &#123;</div><div class="line">      <span class="keyword">case</span> (topic, i) =&amp;gt;</div><div class="line">        println(s&amp;quot;<span class="type">TOPIC</span> $i&amp;quot;)</div><div class="line">        topic.foreach &#123; <span class="keyword">case</span> (term, weight) =&amp;gt; println(s&amp;quot;$term\t$weight&amp;quot;) &#125;</div><div class="line">        println(s&amp;quot;==========&amp;quot;)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">preprocess</span></span>(dataset: <span class="type">DataFrame</span>, inputCol: <span class="type">String</span>, sc: <span class="type">SparkContext</span>, vocabSize: <span class="type">Int</span>): (<span class="type">RDD</span>[(<span class="type">Long</span>, <span class="type">Vector</span>)], <span class="type">Array</span>[<span class="type">String</span>], <span class="type">PipelineModel</span>) = &#123;</div><div class="line">    <span class="keyword">val</span> stopWordText1 = sc.textFile(sc.getConf.get(&amp;quot;spark.client.stopWordText&amp;quot;)).collect().flatMap(_.stripMargin.split(&amp;quot;\\s+&amp;quot;))</div><div class="line">    <span class="keyword">val</span> stopWordText2 = sc.textFile(sc.getConf.get(&amp;quot;spark.client.stopWordText2&amp;quot;)).collect().flatMap(_.stripMargin.split(&amp;quot;\\s+&amp;quot;))</div><div class="line">    <span class="keyword">val</span> data = dataset.na.drop()</div><div class="line">    <span class="comment">// ----------------Pipeline stages---------------------------------------------</span></div><div class="line">    <span class="comment">// - tokenizer--&amp;gt;stopWordsRemover1--&amp;gt;stemmer--&amp;gt;stopWordRemover2--&amp;gt;AccentRemover</span></div><div class="line">    <span class="comment">// 简单分词-&amp;gt;删除无用词汇-&amp;gt;词根-&amp;gt;删除无用词汇-&amp;gt;删除重音符号</span></div><div class="line">    <span class="comment">// ----------------------------------------------------------------------------</span></div><div class="line">    <span class="keyword">val</span> tokenizer = <span class="keyword">new</span> <span class="type">RegexTokenizer</span>()</div><div class="line">      .setInputCol(inputCol)</div><div class="line">      .setPattern(&amp;quot;[a-z0<span class="number">-9</span>éèêâîûùäüïëô]+&amp;quot;)</div><div class="line">      .setGaps(<span class="literal">false</span>)</div><div class="line">      .setOutputCol(&amp;quot;rawTokens&amp;quot;)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> stopWordsRemover1 = <span class="keyword">new</span> <span class="type">StopWordsRemover</span>()</div><div class="line">      .setInputCol(&amp;quot;rawTokens&amp;quot;)</div><div class="line">      .setOutputCol(&amp;quot;tokens&amp;quot;)</div><div class="line">    stopWordsRemover1.setStopWords(stopWordsRemover1.getStopWords ++ stopWordText1)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> stemmer = <span class="keyword">new</span> <span class="type">Stemmer</span>()</div><div class="line">      .setInputCol(&amp;quot;tokens&amp;quot;)</div><div class="line">      .setOutputCol(&amp;quot;stemmed&amp;quot;)</div><div class="line">      .setLanguage(&amp;quot;<span class="type">French</span>&amp;quot;)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> stopWordsRemover2 = <span class="keyword">new</span> <span class="type">StopWordsRemover</span>()</div><div class="line">      .setInputCol(&amp;quot;stemmed&amp;quot;)</div><div class="line">      .setOutputCol(&amp;quot;tokens2&amp;quot;)</div><div class="line">    stopWordsRemover2.setStopWords(stopWordsRemover2.getStopWords ++ stopWordText2)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> accentRemover = <span class="keyword">new</span> <span class="type">AccentRemover</span>()</div><div class="line">      .setInputCol(&amp;quot;tokens2&amp;quot;)</div><div class="line">      .setOutputCol(&amp;quot;mot&amp;quot;)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> countVectorizer = <span class="keyword">new</span> <span class="type">CountVectorizer</span>()</div><div class="line">      .setVocabSize(vocabSize)</div><div class="line">      .setInputCol(&amp;quot;mot&amp;quot;)</div><div class="line">      .setOutputCol(&amp;quot;features&amp;quot;)</div><div class="line">    <span class="comment">//------------------------------------------------------</span></div><div class="line">    <span class="comment">//stage 0,1,2,3,4,5</span></div><div class="line">    <span class="keyword">val</span> pipeline = <span class="keyword">new</span> <span class="type">Pipeline</span>().setStages(<span class="type">Array</span>(</div><div class="line">      tokenizer, <span class="comment">//stage 0</span></div><div class="line">      stopWordsRemover1, <span class="comment">//1</span></div><div class="line">      stemmer, <span class="comment">//2</span></div><div class="line">      stopWordsRemover2, <span class="comment">//3</span></div><div class="line">      accentRemover, <span class="comment">//4</span></div><div class="line">      countVectorizer <span class="comment">//stage 5</span></div><div class="line">      ))</div><div class="line"></div><div class="line">    <span class="comment">// creates the PipeLineModel to use for the dataset transformation</span></div><div class="line">    <span class="keyword">val</span> model = pipeline.fit(data)</div><div class="line">    <span class="comment">// countVectorizer stage ==&amp;gt; 5</span></div><div class="line">    <span class="keyword">val</span> vocabArray = model.stages(<span class="number">5</span>).asInstanceOf[<span class="type">CountVectorizerModel</span>].vocabulary</div><div class="line">    sc.parallelize(vocabArray).saveAsTextFile(sc.getConf.get(&amp;quot;spark.client.vocab&amp;quot;))</div><div class="line">    <span class="keyword">val</span> documents = model.transform(data)</div><div class="line">      .select(&amp;quot;features&amp;quot;)</div><div class="line">      .rdd</div><div class="line">      .map &#123; <span class="keyword">case</span> <span class="type">Row</span>(features: <span class="type">Vector</span>) =&amp;gt; features &#125;</div><div class="line">      .zipWithIndex()</div><div class="line">      .map(_.swap)</div><div class="line"></div><div class="line">    (documents, vocabArray, model)</div><div class="line">&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>最重要的步骤就是<code>tokenizer--&gt;stopWordsRemover1--&gt;stemmer--&gt;stopWordRemover2--&gt;AccentRemover</code> 处理完成之后，需要transform成dataframe的类型。<br>这样就可以使用LDA里面的算法进行筛选TOPIC了，这里我选择100个TOPIC迭代100次，这很花时间的。<br>最后会打印出来。每个TOPIC都是不同的，LDAOptimizer 有两种算法，一种是em算法，一种是online算法，这里选择online算法，因em算法的问题导致之前结果的TOPIC是重复的。</p>
<p><img src="http://blog.qfdk.me/_image/2016-09-20-19-45-43.jpg" alt=""></p>
<p>这个结果就可以进行预测了，每个TOPIC都是不同的。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://qfdk.github.io/2016/09/20/2016-09-20/" data-id="ciuehhbhw0000su9kwjm6fvm1" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Apache-Spark/">Apache Spark</a></li></ul>

    </footer>
  </div>
  
    
  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Bigdata/">Bigdata</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Apache-Spark/">Apache Spark</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Apache-Spark/" style="font-size: 10px;">Apache Spark</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/09/20/2016-09-20/">Apache Spark with Pipeline and LDA</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 qfdk<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>